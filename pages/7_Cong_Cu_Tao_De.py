import os
import io
import math
import json
import pdfplumber
import tempfile
import streamlit as st
import openai
import requests
from docx import Document
from bs4 import BeautifulSoup
from zipfile import ZipFile
from typing import Tuple, List

# ------------------------- CONFIG -------------------------
st.set_page_config(page_title="Táº¡o Ä‘á» & Ma tráº­n (AI)", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ Táº¡o ma tráº­n & Ä‘á» kiá»ƒm tra â€” upload sÃ¡ch, cÃ´ng vÄƒn, máº«u Ä‘á» â†’ AI tráº£ vá» ma tráº­n & Ä‘á»")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # báº¡n cÃ³ thá»ƒ thay model á»Ÿ env

if not OPENAI_API_KEY:
    st.error("Cáº§n thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng OPENAI_API_KEY trÆ°á»›c khi cháº¡y.")
    st.stop()
openai.api_key = OPENAI_API_KEY

# ------------------------- HELPERS: Táº¬P TIN -> TEXT -------------------------
def extract_text_from_pdf(file_bytes: bytes) -> str:
    text_parts = []
    try:
        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text_parts.append(page_text)
    except Exception as e:
        st.warning(f"KhÃ´ng thá»ƒ Ä‘á»c PDF bÃ¬nh thÆ°á»ng: {e}.")
    return "\n".join(text_parts)

def extract_text_from_docx(file_bytes: bytes) -> str:
    # python-docx cáº§n file path
    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
        tmp.write(file_bytes)
        tmp.flush()
        doc = Document(tmp.name)
        paragraphs = [p.text for p in doc.paragraphs if p.text and p.text.strip()]
    return "\n".join(paragraphs)

def extract_text_from_file(uploaded) -> Tuple[str, str]:
    """
    Tráº£ vá» (mime_hint, text)
    uploaded: Streamlit UploadedFile
    """
    raw = uploaded.read()
    name_lower = uploaded.name.lower()
    # heuristics
    if name_lower.endswith(".pdf"):
        return ("application/pdf", extract_text_from_pdf(raw))
    if name_lower.endswith(".docx"):
        return ("application/vnd.openxmlformats-officedocument.wordprocessingml.document", extract_text_from_docx(raw))
    if name_lower.endswith(".doc"):
        # try docx extraction fallback (some .doc can't read)
        try:
            return ("application/msword", extract_text_from_docx(raw))
        except Exception:
            return ("application/msword", raw.decode(errors="ignore"))
    # otherwise try to decode as text
    try:
        return ("text/plain", raw.decode("utf-8"))
    except Exception:
        return ("application/octet-stream", raw.decode(errors="ignore"))

# ------------------------- HELPERS: KHOáº¢NG Cáº®T/TÃ“M Táº®T -------------------------
def chunk_text(text: str, max_chars: int = 30000) -> List[str]:
    """Chia text lá»›n thÃ nh cÃ¡c chunk <= max_chars theo khoáº£ng xuá»‘ng dÃ²ng."""
    if not text:
        return []
    parts = []
    cur = ""
    for paragraph in text.split("\n\n"):
        if len(cur) + len(paragraph) + 2 <= max_chars:
            cur += paragraph + "\n\n"
        else:
            if cur:
                parts.append(cur)
            # náº¿u paragraph quÃ¡ dÃ i váº«n pháº£i chia
            while len(paragraph) > max_chars:
                parts.append(paragraph[:max_chars])
                paragraph = paragraph[max_chars:]
            cur = paragraph + "\n\n"
    if cur.strip():
        parts.append(cur)
    return parts

def summarize_long_texts(chunks: List[str]) -> str:
    """
    Gá»i OpenAI Ä‘á»ƒ tÃ³m táº¯t tá»«ng chunk rá»“i ghÃ©p láº¡i.
    Tráº£ vá» má»™t báº£n tÃ³m táº¯t há»£p nháº¥t.
    """
    summaries = []
    system = "Báº¡n lÃ  trá»£ lÃ½ tÃ³m táº¯t vÄƒn báº£n, giá»¯ láº¡i cÃ¡c Ã½ chÃ­nh, chá»§ Ä‘á», tiÃªu Ä‘á» chÆ°Æ¡ng/bÃ i náº¿u cÃ³."
    for c in chunks:
        prompt = f"TÃ³m táº¯t ná»™i dung sau thÃ nh Ä‘oáº¡n ngáº¯n 3-6 cÃ¢u, liá»‡t kÃª cÃ¡c chá»§ Ä‘á» chÃ­nh (náº¿u cÃ³):\n\n{c[:60000]}"
        try:
            resp = openai.ChatCompletion.create(
                model=OPENAI_MODEL,
                messages=[{"role": "system", "content": system},
                          {"role": "user", "content": prompt}],
                max_tokens=600,
                temperature=0.2
            )
            text = resp.choices[0].message.content.strip()
            summaries.append(text)
        except Exception as e:
            summaries.append(c[:1000])  # fallback: giá»¯ Ä‘oáº¡n Ä‘áº§u
    # GhÃ©p cÃ¡c summary
    joined = "\n\n".join(summaries)
    # Náº¿u váº«n quÃ¡ dÃ i, cáº¯t ngáº¯n
    if len(joined) > 30000:
        return joined[:30000]
    return joined

# ------------------------- HELPERS: Gá»ŒI OPENAI -------------------------
def call_openai_generate_matrix_and_exam(textbook_text: str, official_doc_text: str, template_text: str, instruction: str) -> dict:
    """
    XÃ¢y prompt rÃµ rÃ ng, yÃªu cáº§u tráº£ vá» JSON:
    {"matrixHtml": "...", "examHtml": "..."}
    """
    # Báº£o Ä‘áº£m khÃ´ng quÃ¡ dÃ i: náº¿u lá»›n, tÃ³m táº¯t
    combined_len = len(textbook_text or "") + len(official_doc_text or "") + len(template_text or "")
    if combined_len > 90000:
        # chunk vÃ  summarize
        tb_chunks = chunk_text(textbook_text, max_chars=30000)
        textbook_text = summarize_long_texts(tb_chunks)
        off_chunks = chunk_text(official_doc_text, max_chars=30000)
        official_doc_text = summarize_long_texts(off_chunks)
        tpl_chunks = chunk_text(template_text, max_chars=20000)
        template_text = summarize_long_texts(tpl_chunks)

    system_msg = (
        "Báº¡n lÃ  má»™t trá»£ lÃ½ chuyÃªn táº¡o MA TRáº¬N (dáº¡ng báº£ng HTML) vÃ  Äá»€ KIá»‚M TRA (HTML) "
        "theo Ä‘Ãºng MáºªU Ä‘á» Ä‘Æ°á»£c cung cáº¥p. LuÃ´n tráº£ vá» Ä‘Ãºng **JSON** há»£p lá»‡ duy nháº¥t "
        "khÃ´ng cÃ³ text phá»¥ ngoÃ i JSON, cÃ³ hai khoÃ¡: matrixHtml vÃ  examHtml. "
        "matrixHtml pháº£i lÃ  má»™t Ä‘oáº¡n HTML chá»©a báº£ng ma tráº­n (cÃ¡c Ã´, tiÃªu Ä‘á»), "
        "examHtml pháº£i lÃ  HTML chá»©a Ä‘á» kiá»ƒm tra Ä‘áº§y Ä‘á»§ theo máº«u."
    )

    user_msg = (
        "DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung trÃ­ch xuáº¥t tá»« cÃ¡c file mÃ  ngÆ°á»i dÃ¹ng upload.\n\n"
        f"=== Textbook (SGK) ===\n{(textbook_text[:50000] + '...') if len(textbook_text)>50000 else textbook_text}\n\n"
        f"=== Official doc (CÃ´ng vÄƒn) ===\n{(official_doc_text[:20000]+'...') if len(official_doc_text)>20000 else official_doc_text}\n\n"
        f"=== Template (MáºªU Äá»€) ===\n{(template_text[:20000]+'...') if len(template_text)>20000 else template_text}\n\n"
        f"=== YÃªu cáº§u ngÆ°á»i dÃ¹ng ===\n{instruction}\n\n"
        "YÃªu cáº§u cá»¥ thá»ƒ:\n"
        "1) Sinh MA TRáº¬N (matrixHtml) phÃ¹ há»£p vá»›i ná»™i dung vÃ  phÃ¢n bá»• 21 cÃ¢u (theo CV/tiÃªu chÃ­ ngÆ°á»i dÃ¹ng náº¿u cÃ³).\n"
        "2) Sinh Äá»€ (examHtml) Ä‘Ãºng cáº¥u trÃºc máº«u Ä‘á» (tiÃªu Ä‘á», pháº§n tráº¯c nghiá»‡m/tn, pháº§n tá»± luáº­n...), "
        "Ä‘áº£m báº£o sá»‘ cÃ¢u / Ä‘iá»ƒm khá»›p vá»›i ma tráº­n. KhÃ´ng chÃ¨n thÃ´ng tin bÃ­ máº­t.\n\n"
        "Output MUST be valid JSON, for example:\n"
        '{"matrixHtml":"<table>...</table>", "examHtml":"<div>...</div>"}\n'
        "Náº¿u khÃ´ng thá»ƒ táº¡o Ä‘áº§y Ä‘á»§ cÃ¢u há»i vÃ¬ nguá»“n khÃ´ng Ä‘á»§, ghi chÃº trong examHtml lÃ½ do (dÆ°á»›i dáº¡ng comment HTML)."
    )

    try:
        resp = openai.ChatCompletion.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ],
            max_tokens=4500,
            temperature=0.2
        )
        raw = resp.choices[0].message.content.strip()
    except Exception as e:
        raise RuntimeError(f"Lá»—i gá»i OpenAI: {e}")

    # TRY parse as JSON; náº¿u model tráº£ thÃªm text trÆ°á»›c/sau JSON thÃ¬ cá»‘ gáº¯ng extract {...}
    try:
        parsed = json.loads(raw)
        return parsed
    except json.JSONDecodeError:
        # tÃ¬m dáº¥u ngoáº·c JSON Ä‘áº§u tiÃªn
        start = raw.find("{")
        end = raw.rfind("}")
        if start != -1 and end != -1 and end > start:
            try:
                parsed = json.loads(raw[start:end+1])
                return parsed
            except Exception:
                pass
    # Náº¿u khÃ´ng parse Ä‘Æ°á»£c, raise Ä‘á»ƒ debug (kÃ¨m raw)
    raise RuntimeError("OpenAI tráº£ vá» khÃ´ng pháº£i JSON há»£p lá»‡. Ná»™i dung tráº£ vá» (rÃºt gá»n):\n" + raw[:2000])

# ------------------------- HELPERS: HTML -> DOCX/HTML xuáº¥t file -------------------------
def html_to_plain_text(html: str) -> str:
    if not html:
        return ""
    soup = BeautifulSoup(html, "html.parser")
    # giá»¯ má»™t sá»‘ tag tiÃªu Ä‘á», li, p thÃ nh text vá»›i xuá»‘ng dÃ²ng
    for br in soup.find_all("br"):
        br.replace_with("\n")
    texts = []
    for el in soup.find_all(["h1","h2","h3","h4","p","li","tr","td"]):
        txt = el.get_text(separator=" ", strip=True)
        if txt:
            texts.append(txt)
    plain = "\n\n".join(texts)
    return plain

def make_docx_from_htmls(matrix_html: str, exam_html: str, meta_title: str="Äá»€ KIá»‚M TRA") -> bytes:
    doc = Document()
    doc.add_heading(meta_title, level=1)
    doc.add_heading("I. MA TRáº¬N", level=2)
    if matrix_html:
        matrix_text = html_to_plain_text(matrix_html)
        for line in matrix_text.split("\n\n"):
            doc.add_paragraph(line)
    else:
        doc.add_paragraph("KhÃ´ng cÃ³ ma tráº­n")

    doc.add_page_break()
    doc.add_heading("II. Äá»€ KIá»‚M TRA", level=2)
    if exam_html:
        exam_text = html_to_plain_text(exam_html)
        for line in exam_text.split("\n\n"):
            doc.add_paragraph(line)
    else:
        doc.add_paragraph("KhÃ´ng cÃ³ Ä‘á»")
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.read()

# ------------------------- STREAMLIT UI -------------------------
st.markdown("""
**HÆ°á»›ng dáº«n:** Upload 3 file (SGK, CÃ´ng vÄƒn, Máº«u Ä‘á»). Nháº­p ghi chÃº / yÃªu cáº§u (vÃ­ dá»¥: 'táº¡o ma tráº­n 21 cÃ¢u, 10 Ä‘iá»ƒm, tá»‰ lá»‡ 25/25/50; format theo máº«u Ä‘á»ƒ in A4'). 
Sau Ä‘Ã³ báº¥m **Táº O** Ä‘á»ƒ AI sinh ma tráº­n vÃ  Ä‘á».
""")

col1, col2 = st.columns(2)
with col1:
    uploaded_textbook = st.file_uploader("1) Táº£i lÃªn: SÃ¡ch giÃ¡o khoa (PDF/DOCX)", type=['pdf','docx','doc'], key='tb')
    uploaded_official = st.file_uploader("2) Táº£i lÃªn: CÃ´ng vÄƒn / CÃ´ng bá»‘ (PDF/DOCX)", type=['pdf','docx','doc'], key='cv')

with col2:
    uploaded_template = st.file_uploader("3) Táº£i lÃªn: Máº«u Ä‘á» kiá»ƒm tra (PDF/DOCX)", type=['pdf','docx','doc'], key='tpl')
    instruction = st.text_area("YÃªu cáº§u / Ghi chÃº cho AI (báº¯t buá»™c)", value="Táº¡o ma tráº­n 21 cÃ¢u, 10 Ä‘iá»ƒm; format theo máº«u; phÃ¢n bá»• 6 NB, 8 TH, 7 VÄ/VÄC", height=120)

if st.button("ğŸš€ Táº O MA TRáº¬N & Äá»€"):
    if not uploaded_textbook or not uploaded_official or not uploaded_template:
        st.error("Vui lÃ²ng táº£i lÃªn Ä‘á»§ 3 file: SGK, CÃ´ng vÄƒn, Máº«u Ä‘á».")
    else:
        with st.spinner("Äang trÃ­ch xuáº¥t ná»™i dung tá»« file..."):
            tb_mime, tb_text = extract_text_from_file(uploaded_textbook)
            cv_mime, cv_text = extract_text_from_file(uploaded_official)
            tpl_mime, tpl_text = extract_text_from_file(uploaded_template)

        # hiá»ƒn thá»‹ kÃ­ch thÆ°á»›c / pháº§n trÃ­ch xuáº¥t
        st.info(f"ÄÃ£ trÃ­ch xuáº¥t: SGK ~{len(tb_text)} kÃ½ tá»± | CÃ´ng vÄƒn ~{len(cv_text)} kÃ½ tá»± | Máº«u Ä‘á» ~{len(tpl_text)} kÃ½ tá»±")

        try:
            with st.spinner("Gá»i AI Ä‘á»ƒ táº¡o ma tráº­n & Ä‘á»... (cÃ³ thá»ƒ máº¥t 10-40s tÃ¹y model)"):
                result = call_openai_generate_matrix_and_exam(tb_text, cv_text, tpl_text, instruction)
        except Exception as e:
            st.exception(e)
            st.stop()

        # Validate result
        matrix_html = result.get("matrixHtml") or result.get("matrix") or ""
        exam_html = result.get("examHtml") or result.get("exam") or ""
        if not matrix_html and not exam_html:
            st.error("AI khÃ´ng tráº£ vá» matrixHtml hoáº·c examHtml.")
            st.write(result)
            st.stop()

        st.success("HoÃ n táº¥t: AI tráº£ vá» káº¿t quáº£. Hiá»ƒn thá»‹ bÃªn dÆ°á»›i.")

        # Hiá»ƒn thá»‹ Ma tráº­n
        st.markdown("---")
        st.subheader("ğŸ“Š Ma tráº­n (xem trÆ°á»›c HTML)")
        try:
            st.components.v1.html(matrix_html, height=360, scrolling=True)
        except Exception:
            st.markdown(matrix_html, unsafe_allow_html=True)

        # Hiá»ƒn thá»‹ Äá»
        st.markdown("---")
        st.subheader("ğŸ“„ Äá» kiá»ƒm tra (xem trÆ°á»›c HTML)")
        try:
            st.components.v1.html(exam_html, height=540, scrolling=True)
        except Exception:
            st.markdown(exam_html, unsafe_allow_html=True)

        # Táº£i file HTML
        st.markdown("---")
        st.download_button("ğŸ“¥ Táº£i HTML - Ma tráº­n", data=matrix_html.encode('utf-8'), file_name="matrix.html", mime="text/html")
        st.download_button("ğŸ“¥ Táº£i HTML - Äá»", data=exam_html.encode('utf-8'), file_name="exam.html", mime="text/html")

        # Táº¡o vÃ  táº£i DOCX tá»« HTML (chuyá»ƒn HTML -> plain text -> docx)
        docx_bytes = make_docx_from_htmls(matrix_html, exam_html, meta_title=f"Äá»€ - Generated")
        st.download_button("ğŸ“¥ Táº£i DOCX (Ma tráº­n + Äá»)", data=docx_bytes, file_name=f"De_MaTran_Generated.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

        # Show raw JSON (collapsed)
        with st.expander("ğŸ”§ (Raw) JSON tráº£ vá» tá»« AI"):
            st.json(result)
