import os
import io
import math
import json
import tempfile
import streamlit as st
import requests
from typing import Tuple, List

# --- Xá»­ lÃ½ Import Error ---
# Pháº§n nÃ y giÃºp bÃ¡o lá»—i rÃµ rÃ ng trÃªn giao diá»‡n náº¿u thiáº¿u thÆ° viá»‡n
try:
    import pdfplumber
    import openai
    from docx import Document
    from bs4 import BeautifulSoup
except ImportError as e:
    st.error(f"Lá»—i thiáº¿u thÆ° viá»‡n: {e}")
    st.info("Vui lÃ²ng Ä‘áº£m báº£o file 'requirements.txt' Ä‘Ã£ cÃ³ Ä‘áº§y Ä‘á»§: pdfplumber, openai, python-docx, beautifulsoup4")
    st.stop()

# ------------------------- CONFIG -------------------------
st.set_page_config(page_title="Táº¡o Ä‘á» & Ma tráº­n (AI)", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ Táº¡o ma tráº­n & Ä‘á» kiá»ƒm tra â€” upload sÃ¡ch, cÃ´ng vÄƒn, máº«u Ä‘á» â†’ AI tráº£ vá» ma tráº­n & Ä‘á»")

# Láº¥y API Key tá»« Secrets hoáº·c biáº¿n mÃ´i trÆ°á»ng
# Æ¯u tiÃªn láº¥y tá»« st.secrets náº¿u cháº¡y trÃªn Streamlit Cloud
if "OPENAI_API_KEY" in st.secrets:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
else:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini") 

if not OPENAI_API_KEY:
    st.warning("âš ï¸ ChÆ°a tÃ¬m tháº¥y API Key.")
    st.markdown("""
    **CÃ¡ch kháº¯c phá»¥c:**
    1. Náº¿u cháº¡y Local: Táº¡o biáº¿n mÃ´i trÆ°á»ng `OPENAI_API_KEY`.
    2. Náº¿u cháº¡y Streamlit Cloud: VÃ o **Settings** > **Secrets** vÃ  thÃªm:
    ```toml
    OPENAI_API_KEY = "sk-..."
    ```
    """)
    st.stop()
else:
    openai.api_key = OPENAI_API_KEY

# ------------------------- HELPERS: Táº¬P TIN -> TEXT -------------------------
def extract_text_from_pdf(file_bytes: bytes) -> str:
    text_parts = []
    try:
        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text_parts.append(page_text)
    except Exception as e:
        st.warning(f"KhÃ´ng thá»ƒ Ä‘á»c PDF bÃ¬nh thÆ°á»ng: {e}.")
    return "\n".join(text_parts)

def extract_text_from_docx(file_bytes: bytes) -> str:
    # python-docx cáº§n file path hoáº·c file-like object
    try:
        # CÃ¡ch 1: DÃ¹ng BytesIO trá»±c tiáº¿p (nhanh hÆ¡n, khÃ´ng cáº§n tempfile)
        doc = Document(io.BytesIO(file_bytes))
        paragraphs = [p.text for p in doc.paragraphs if p.text and p.text.strip()]
        return "\n".join(paragraphs)
    except Exception:
        # Fallback: DÃ¹ng tempfile náº¿u cÃ¡ch trÃªn lá»—i
        with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
            tmp.write(file_bytes)
            tmp.flush()
            try:
                doc = Document(tmp.name)
                paragraphs = [p.text for p in doc.paragraphs if p.text and p.text.strip()]
                return "\n".join(paragraphs)
            finally:
                os.unlink(tmp.name)

def extract_text_from_file(uploaded) -> Tuple[str, str]:
    """
    Tráº£ vá» (mime_hint, text)
    uploaded: Streamlit UploadedFile
    """
    if uploaded is None:
        return ("", "")
        
    raw = uploaded.read()
    name_lower = uploaded.name.lower()
    
    # Reset pointer sau khi read (quan trá»ng náº¿u cáº§n Ä‘á»c láº¡i)
    uploaded.seek(0)
    
    # heuristics
    if name_lower.endswith(".pdf"):
        return ("application/pdf", extract_text_from_pdf(raw))
    if name_lower.endswith(".docx"):
        return ("application/vnd.openxmlformats-officedocument.wordprocessingml.document", extract_text_from_docx(raw))
    if name_lower.endswith(".doc"):
        # File .doc cÅ© ráº¥t khÃ³ Ä‘á»c báº±ng python thuáº§n, thá»­ Ä‘á»c nhÆ° docx hoáº·c text
        try:
            return ("application/msword", extract_text_from_docx(raw))
        except Exception:
            # Fallback sang text decode
            return ("application/msword", raw.decode(errors="ignore"))
            
    # otherwise try to decode as text
    try:
        return ("text/plain", raw.decode("utf-8"))
    except Exception:
        return ("application/octet-stream", raw.decode(errors="ignore"))

# ------------------------- HELPERS: KHOáº¢NG Cáº®T/TÃ“M Táº®T -------------------------
def chunk_text(text: str, max_chars: int = 30000) -> List[str]:
    """Chia text lá»›n thÃ nh cÃ¡c chunk <= max_chars theo khoáº£ng xuá»‘ng dÃ²ng."""
    if not text:
        return []
    parts = []
    cur = ""
    for paragraph in text.split("\n\n"):
        if len(cur) + len(paragraph) + 2 <= max_chars:
            cur += paragraph + "\n\n"
        else:
            if cur:
                parts.append(cur)
            # náº¿u paragraph quÃ¡ dÃ i váº«n pháº£i chia
            while len(paragraph) > max_chars:
                parts.append(paragraph[:max_chars])
                paragraph = paragraph[max_chars:]
            cur = paragraph + "\n\n"
    if cur.strip():
        parts.append(cur)
    return parts

def summarize_long_texts(chunks: List[str]) -> str:
    """
    Gá»i OpenAI Ä‘á»ƒ tÃ³m táº¯t tá»«ng chunk rá»“i ghÃ©p láº¡i.
    Tráº£ vá» má»™t báº£n tÃ³m táº¯t há»£p nháº¥t.
    """
    summaries = []
    system = "Báº¡n lÃ  trá»£ lÃ½ tÃ³m táº¯t vÄƒn báº£n giÃ¡o dá»¥c, giá»¯ láº¡i cÃ¡c Ã½ chÃ­nh, chá»§ Ä‘á», ná»™i dung bÃ i há»c."
    
    progress_text = st.empty()
    
    for i, c in enumerate(chunks):
        progress_text.text(f"Äang tÃ³m táº¯t pháº§n {i+1}/{len(chunks)}...")
        prompt = f"TÃ³m táº¯t ná»™i dung sau thÃ nh cÃ¡c gáº¡ch Ä‘áº§u dÃ²ng chi tiáº¿t vá» kiáº¿n thá»©c:\n\n{c[:50000]}"
        try:
            # Sá»­ dá»¥ng cÃº phÃ¡p cÅ© (openai<1.0.0) nhÆ° yÃªu cáº§u cá»§a user
            resp = openai.ChatCompletion.create(
                model=OPENAI_MODEL,
                messages=[{"role": "system", "content": system},
                          {"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.2
            )
            text = resp.choices[0].message.content.strip()
            summaries.append(text)
        except Exception as e:
            summaries.append(c[:2000])  # fallback: giá»¯ Ä‘oáº¡n Ä‘áº§u
            
    progress_text.empty()
    
    # GhÃ©p cÃ¡c summary
    joined = "\n\n".join(summaries)
    if len(joined) > 30000:
        return joined[:30000]
    return joined

# ------------------------- HELPERS: Gá»ŒI OPENAI -------------------------
def call_openai_generate_matrix_and_exam(textbook_text: str, official_doc_text: str, template_text: str, instruction: str) -> dict:
    # Báº£o Ä‘áº£m khÃ´ng quÃ¡ dÃ i: náº¿u lá»›n, tÃ³m táº¯t
    combined_len = len(textbook_text or "") + len(official_doc_text or "") + len(template_text or "")
    
    # NgÆ°á»¡ng token Æ°á»›c tÃ­nh (1 char ~ 0.25 token, 90k chars ~ 22k tokens). 
    # GPT-4o-mini context window lÃ  128k, nhÆ°ng output bá»‹ giá»›i háº¡n.
    if combined_len > 80000:
        st.info("Ná»™i dung quÃ¡ dÃ i, há»‡ thá»‘ng Ä‘ang tá»± Ä‘á»™ng tÃ³m táº¯t bá»›t...")
        tb_chunks = chunk_text(textbook_text, max_chars=30000)
        textbook_text = summarize_long_texts(tb_chunks) if len(textbook_text) > 30000 else textbook_text
        
        # Chá»‰ tÃ³m táº¯t SGK lÃ  chá»§ yáº¿u, cÃ´ng vÄƒn vÃ  máº«u Ä‘á» nÃªn giá»¯ nguyÃªn náº¿u cÃ³ thá»ƒ
        if len(official_doc_text) > 30000:
             off_chunks = chunk_text(official_doc_text, max_chars=30000)
             official_doc_text = summarize_long_texts(off_chunks)

    system_msg = (
        "Báº¡n lÃ  má»™t chuyÃªn gia giÃ¡o dá»¥c chuyÃªn táº¡o MA TRáº¬N (dáº¡ng báº£ng HTML) vÃ  Äá»€ KIá»‚M TRA (HTML) "
        "theo Ä‘Ãºng MáºªU Ä‘á» Ä‘Æ°á»£c cung cáº¥p. "
        "Output báº¯t buá»™c lÃ  JSON há»£p lá»‡, cÃ³ hai khoÃ¡: 'matrixHtml' vÃ  'examHtml'.\n"
        "- 'matrixHtml': HTML table ma tráº­n Ä‘áº·c táº£ ká»¹ thuáº­t.\n"
        "- 'examHtml': HTML Ä‘á» thi hoÃ n chá»‰nh (Tráº¯c nghiá»‡m + Tá»± luáº­n).\n"
        "Tuyá»‡t Ä‘á»‘i khÃ´ng tráº£ vá» markdown block (```json), chá»‰ tráº£ vá» raw JSON string."
    )

    user_msg = (
        "DÆ°á»›i Ä‘Ã¢y lÃ  tÃ i liá»‡u nguá»“n:\n\n"
        f"=== Ná»˜I DUNG SGK (Kiáº¿n thá»©c nguá»“n) ===\n{textbook_text}\n\n"
        f"=== CÃ”NG VÄ‚N / KHUNG CHÆ¯Æ NG TRÃŒNH ===\n{official_doc_text}\n\n"
        f"=== MáºªU Äá»€ (Template Format) ===\n{template_text}\n\n"
        f"=== YÃŠU Cáº¦U Cá»¦A GIÃO VIÃŠN ===\n{instruction}\n\n"
        "HÃ£y thá»±c hiá»‡n:\n"
        "1. XÃ¢y dá»±ng MA TRáº¬N Ä‘á» thi (matrixHtml) phÃ¹ há»£p vá»›i cÃ´ng vÄƒn vÃ  yÃªu cáº§u.\n"
        "2. Soáº¡n Äá»€ THI (examHtml) dá»±a trÃªn ma tráº­n vá»«a táº¡o. Ná»™i dung cÃ¢u há»i láº¥y tá»« SGK. HÃ¬nh thá»©c trÃ¬nh bÃ y giá»‘ng Máº«u Äá».\n"
        "Output format: JSON { \"matrixHtml\": \"...\", \"examHtml\": \"...\" }"
    )

    try:
        resp = openai.ChatCompletion.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ],
            # TÄƒng max_tokens Ä‘á»ƒ Ä‘áº£m báº£o JSON khÃ´ng bá»‹ cáº¯t giá»¯a chá»«ng
            max_tokens=10000 if "gpt-4" in OPENAI_MODEL else 4000, 
            temperature=0.3
        )
        raw = resp.choices[0].message.content.strip()
    except Exception as e:
        raise RuntimeError(f"Lá»—i gá»i OpenAI: {e}")

    # Xá»­ lÃ½ lÃ m sáº¡ch chuá»—i JSON náº¿u model lá»¡ thÃªm markdown block
    cleaned_raw = raw.replace("```json", "").replace("```", "").strip()

    try:
        parsed = json.loads(cleaned_raw)
        return parsed
    except json.JSONDecodeError:
        # Fallback: Cá»‘ gáº¯ng tÃ¬m chuá»—i JSON trong text há»—n táº¡p
        start = raw.find("{")
        end = raw.rfind("}")
        if start != -1 and end != -1 and end > start:
            try:
                parsed = json.loads(raw[start:end+1])
                return parsed
            except Exception:
                pass
        raise RuntimeError(f"OpenAI tráº£ vá» khÃ´ng pháº£i JSON há»£p lá»‡.\nRaw: {raw[:500]}...")

# ------------------------- HELPERS: HTML -> DOCX -------------------------
def html_to_plain_text(html: str) -> str:
    if not html:
        return ""
    soup = BeautifulSoup(html, "html.parser")
    # Thay tháº¿ br báº±ng xuá»‘ng dÃ²ng
    for br in soup.find_all("br"):
        br.replace_with("\n")
    
    # Láº¥y text
    text = soup.get_text(separator="\n")
    
    # Xá»­ lÃ½ cÃ¡c dÃ²ng trá»‘ng quÃ¡ nhiá»u
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    return "\n".join(lines)

def make_docx_from_htmls(matrix_html: str, exam_html: str) -> bytes:
    doc = Document()
    doc.add_heading("Káº¾T QUáº¢ Táº O Äá»€ Tá»° Äá»˜NG", level=0)
    
    doc.add_heading("I. MA TRáº¬N Äá»€ THI", level=1)
    if matrix_html:
        # ÄÃ¢y lÃ  cÃ¡ch chuyá»ƒn Ä‘á»•i Ä‘Æ¡n giáº£n (text only). 
        # Äá»ƒ giá»¯ báº£ng HTML trong Docx cáº§n thÆ° viá»‡n phá»©c táº¡p hÆ¡n (nhÆ° htmldocx)
        # á» Ä‘Ã¢y ta dÃ¹ng beautifulsoup Ä‘á»ƒ láº¥y text vÃ  giá»¯ cáº¥u trÃºc cÆ¡ báº£n
        matrix_text = html_to_plain_text(matrix_html)
        doc.add_paragraph(matrix_text)
    else:
        doc.add_paragraph("[KhÃ´ng cÃ³ ná»™i dung ma tráº­n]")

    doc.add_page_break()
    
    doc.add_heading("II. Äá»€ KIá»‚M TRA", level=1)
    if exam_html:
        exam_text = html_to_plain_text(exam_html)
        doc.add_paragraph(exam_text)
    else:
        doc.add_paragraph("[KhÃ´ng cÃ³ ná»™i dung Ä‘á»]")
        
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.read()

# ------------------------- STREAMLIT UI -------------------------
st.info("ğŸ’¡ Máº¹o: Nháº­p API Key trong Settings náº¿u cháº¡y trÃªn Cloud Ä‘á»ƒ khÃ´ng pháº£i setup biáº¿n mÃ´i trÆ°á»ng.")

col1, col2 = st.columns(2)
with col1:
    uploaded_textbook = st.file_uploader("1. SÃ¡ch giÃ¡o khoa (Nguá»“n kiáº¿n thá»©c)", type=['pdf','docx','doc'], key='tb')
    uploaded_official = st.file_uploader("2. CÃ´ng vÄƒn / Khung chÆ°Æ¡ng trÃ¬nh", type=['pdf','docx','doc'], key='cv')

with col2:
    uploaded_template = st.file_uploader("3. Máº«u Ä‘á» kiá»ƒm tra (Format)", type=['pdf','docx','doc'], key='tpl')
    instruction = st.text_area("YÃªu cáº§u cá»¥ thá»ƒ (Sá»‘ cÃ¢u, tá»‰ lá»‡, má»©c Ä‘á»™...)", 
                               value="Táº¡o ma tráº­n 21 cÃ¢u (Tráº¯c nghiá»‡m 5Ä‘, Tá»± luáº­n 5Ä‘). Tá»‰ lá»‡ NB/TH/VD: 40/30/30.", 
                               height=120)

if st.button("ğŸš€ Táº O MA TRáº¬N & Äá»€", type="primary"):
    if not uploaded_textbook or not uploaded_official or not uploaded_template:
        st.error("âš ï¸ Vui lÃ²ng táº£i lÃªn Ä‘á»§ 3 file: SGK, CÃ´ng vÄƒn, Máº«u Ä‘á».")
    else:
        with st.status("Äang xá»­ lÃ½...", expanded=True) as status:
            st.write("ğŸ“– Äang Ä‘á»c ná»™i dung file...")
            tb_mime, tb_text = extract_text_from_file(uploaded_textbook)
            cv_mime, cv_text = extract_text_from_file(uploaded_official)
            tpl_mime, tpl_text = extract_text_from_file(uploaded_template)
            
            st.write(f"âœ… ÄÃ£ Ä‘á»c xong: SGK ({len(tb_text)} kÃ½ tá»±), CÃ´ng vÄƒn ({len(cv_text)} kÃ½ tá»±).")
            
            st.write("ğŸ¤– Äang gá»­i dá»¯ liá»‡u cho AI phÃ¢n tÃ­ch vÃ  sinh Ä‘á»...")
            try:
                result = call_openai_generate_matrix_and_exam(tb_text, cv_text, tpl_text, instruction)
                status.update(label="HoÃ n táº¥t!", state="complete", expanded=False)
            except Exception as e:
                status.update(label="Gáº·p lá»—i!", state="error")
                st.error(f"Lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½: {e}")
                st.stop()

        # Validate result
        matrix_html = result.get("matrixHtml") or result.get("matrix") or ""
        exam_html = result.get("examHtml") or result.get("exam") or ""

        if not matrix_html and not exam_html:
            st.error("AI khÃ´ng tráº£ vá» káº¿t quáº£ Ä‘Ãºng Ä‘á»‹nh dáº¡ng.")
            with st.expander("Xem dá»¯ liá»‡u tráº£ vá» tá»« AI"):
                st.write(result)
            st.stop()

        # Hiá»ƒn thá»‹ káº¿t quáº£
        tab1, tab2 = st.tabs(["ğŸ“Š Ma tráº­n", "ğŸ“ Äá» kiá»ƒm tra"])
        
        with tab1:
            st.markdown(matrix_html, unsafe_allow_html=True)
            st.download_button("ğŸ“¥ Táº£i HTML Ma tráº­n", matrix_html, "matran.html", "text/html")
            
        with tab2:
            st.markdown(exam_html, unsafe_allow_html=True)
            st.download_button("ğŸ“¥ Táº£i HTML Äá»", exam_html, "de_kiem_tra.html", "text/html")

        # Táº£i DOCX chung
        docx_bytes = make_docx_from_htmls(matrix_html, exam_html)
        st.markdown("---")
        st.download_button(
            label="ğŸ“¥ Táº¢I Vá»€ FILE WORD (.DOCX)",
            data=docx_bytes,
            file_name="De_Kiem_Tra_AI_Generated.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            type="primary"
        )
