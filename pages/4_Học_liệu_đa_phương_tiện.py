# app.py ‚Äî ·ª®ng d·ª•ng Streamlit: T·ªïng h·ª£p To√°n + AI Features (C·∫≠p nh·∫≠t: t√≠ch h·ª£p m·ª•c l·ª•c l·ªõp 6-9)
import re
import io
import json
import requests
import streamlit as st
from docx import Document
from docx.shared import Inches
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from reportlab.lib.utils import ImageReader
from PIL import Image
import matplotlib.pyplot as plt
from gtts import gTTS  # Th∆∞ vi·ªán m·ªõi ƒë·ªÉ ƒë·ªçc vƒÉn b·∫£n
import os
import unicodedata

# -----------------------
# C·∫•u h√¨nh page
# -----------------------
st.set_page_config(page_title="Tr·ª£ l√Ω To√°n h·ªçc & Gi√°o d·ª•c AI", layout="wide", page_icon="üéì")
st.title("üéì Tr·ª£ l√Ω Gi√°o d·ª•c ƒêa nƒÉng (Gemini API)")

st.markdown("""
<style>
.block-container { padding-top: 1rem; }
.stTabs [data-baseweb="tab-list"] { gap: 2px; }
.stTabs [data-baseweb="tab"] { height: 50px; white-space: pre-wrap; background-color: #f0f2f6; border-radius: 4px 4px 0 0; gap: 1px; padding-top: 10px; padding-bottom: 10px; }
.stTabs [aria-selected="true"] { background-color: #ffffff; border-top: 2px solid #ff4b4b; }
</style>
""", unsafe_allow_html=True)

# -----------------------
# üîë NH·∫¨P GOOGLE API KEY
# =====================

with st.expander("üîë H∆∞·ªõng d·∫´n l·∫•y Google API Key (b·∫•m ƒë·ªÉ xem)"):
    st.markdown("""
### üëâ C√°ch l·∫•y Google API Key ƒë·ªÉ d√πng ·ª©ng d·ª•ng:

1. Truy c·∫≠p: **https://aistudio.google.com/app/apikey**
2. ƒêƒÉng nh·∫≠p Gmail.
3. Nh·∫•n **Create API key**.
4. Copy API Key.
5. D√°n v√†o √¥ b√™n d∆∞·ªõi.

‚ö†Ô∏è Kh√¥ng chia s·∫ª API Key cho ng∆∞·ªùi kh√°c.
""")

st.subheader("üîê Nh·∫≠p Google API Key:")
api_key = st.text_input("Google API Key:", type="password")

if not api_key:
    st.warning("‚ö†Ô∏è Nh·∫≠p API Key ƒë·ªÉ ti·∫øp t·ª•c.")
else:
    st.success("‚úÖ API Key h·ª£p l·ªá!")


# ===============================
# üìå H√ÄM G·ªåI GEMINI
# ===============================

def analyze_real_image(api_key, image, prompt):
    if image.mode == "RGBA":
        image = image.convert("RGB")

    buf = BytesIO()
    image.save(buf, format="JPEG")
    img_b64 = base64.b64encode(buf.getvalue()).decode()

    MODEL = "gemini-2.5-flash"
    URL = f"https://generativelanguage.googleapis.com/v1/models/{MODEL}:generateContent?key={api_key}"

    payload = {
        "contents": [{
            "role": "user",
            "parts": [
                {"text": prompt},
                {"inline_data": {"mime_type": "image/jpeg", "data": img_b64}}
            ]
        }]
    }

    try:
        res = requests.post(URL, json=payload)
        if res.status_code != 200:
            return f"‚ùå L·ªói API {res.status_code}: {res.text}"

        data = res.json()
        if "candidates" not in data:
            return "‚ùå API tr·∫£ v·ªÅ r·ªóng."

        return data["candidates"][0]["content"]["parts"][0]["text"]

    except Exception as e:
        return f"‚ùå L·ªói k·∫øt n·ªëi: {str(e)}"
    MODEL_DEFAULT = st.selectbox("Ch·ªçn model AI:",
                                 ["models/gemini-2.0-flash", "models/gemini-1.5-flash", "models/gemini-1.5-pro"])
    st.info("L∆∞u √Ω: T√≠nh nƒÉng ƒë·ªçc vƒÉn b·∫£n c·∫ßn k·∫øt n·ªëi internet.")

# -----------------------
# ƒê·ªçc v√† ph√¢n t√≠ch file m·ª•c l·ª•c ƒë√£ upload
# -----------------------
DEFAULT_INDEX_PATH = "/mnt/data/m·ª•c l·ª•c to√°n.docx"

def safe_norm(s: str):
    if s is None:
        return ""
    return unicodedata.normalize("NFC", s).strip()

def parse_index_from_docx(path=DEFAULT_INDEX_PATH):
    """
    Tr·∫£ v·ªÅ c·∫•u tr√∫c: { '6': [ {'chapter_title': 'CH∆Ø∆†NG I....', 'lessons': ['B√†i 1. ...', ...]}, ... ],
                       '7': [...], '8': [...], '9': [...] }
    N·∫øu file kh√¥ng t·ªìn t·∫°i, tr·∫£ r·ªóng.
    """
    res = {}
    if not os.path.exists(path):
        return res
    try:
        doc = Document(path)
    except Exception:
        return res

    current_class = None
    current_chapter = None
    for p in doc.paragraphs:
        line = safe_norm(p.text)
        if not line:
            continue
        # ph√°t hi·ªán ti√™u ƒë·ªÅ l·ªõp: "To√°n 6" ho·∫∑c "To√°n 6:" ho·∫∑c "To√°n 6\n"
        m_class = re.match(r'^\s*To[nn]?\s*[:\-]?\s*(\d{1,2})\b', line, flags=re.IGNORECASE)
        # Some files may have "To√°n 6" exactly
        m_class_alt = re.match(r'^\s*To√°n\s*(\d{1,2})\b', line)
        if m_class_alt:
            current_class = m_class_alt.group(1)
            if current_class not in res:
                res[current_class] = []
            current_chapter = None
            continue

        # CH∆Ø∆†NG detection (has word CH∆Ø∆†NG or Ch∆∞∆°ng)
        m_ch = re.match(r'^(CH∆Ø∆†NG|Ch∆∞∆°ng)\s*([IVXLC]+\.?)?(.*)', line)
        if m_ch:
            title = line
            current_chapter = {"chapter_title": title, "lessons": []}
            if current_class is None:
                # if no class heading before, try infer from preceding context:
                # default put under '6' if empty
                current_class = "6"
                if current_class not in res:
                    res[current_class] = []
            res[current_class].append(current_chapter)
            continue

        # B√†i detection: lines starting with 'B√†i' or 'B√†i 1.' etc
        m_bai = re.match(r'^\s*B√†i\s*\d+\.?\s*(.*)', line)
        if m_bai and current_chapter is not None:
            # store the full line (e.g., "B√†i 1. T·∫≠p h·ª£p.")
            current_chapter["lessons"].append(line)
            continue

        # Some files enumerate "B√†i 1. ..." after bullet; also sometimes 'M·ª§C L·ª§C' or 'T·∫≠p 1:' etc ignored.
        # Nothing else needed; continue.
    return res

index_structure = parse_index_from_docx(DEFAULT_INDEX_PATH)

# If parse failed, provide reasonable defaults based on typical classes
if not index_structure:
    # fallback minimal
    index_structure = {
        "6": [{"chapter_title": "CH∆Ø∆†NG I. T·∫¨P H·ª¢P C√ÅC S·ªê T·ª∞ NHI√äN.", "lessons": ["B√†i 1. T·∫≠p h·ª£p.", "B√†i 2. C√°ch ghi s·ªë t·ª± nhi√™n."]}],
        "7": [{"chapter_title": "CH∆Ø∆†NG I. S·ªê H·ªÆU T·ªà.", "lessons": ["B√†i 1. T·∫≠p h·ª£p c√°c s·ªë h·ªØu t·ªâ."]}],
        "8": [{"chapter_title": "CH∆Ø∆†NG I. ƒêA TH·ª®C.", "lessons": ["B√†i 1. ƒê∆°n th·ª©c."]}],
        "9": [{"chapter_title": "Ch∆∞∆°ng I. PH∆Ø∆†NG TR√åNH V√Ä H·ªÜ HAI PH∆Ø∆†NG TR√åNH B·∫¨C NH·∫§T HAI ·∫®N.", "lessons": ["B√†i 1. Kh√°i ni·ªám ph∆∞∆°ng tr√¨nh v√† h·ªá hai ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t hai ·∫©n."]}],
    }

# -----------------------
# H·ªñ TR·ª¢ LaTeX ‚Üí ·∫£nh (GI·ªÆ NGUY√äN)
# -----------------------
LATEX_RE = re.compile(r"\$\$(.+?)\$\$", re.DOTALL)

def find_latex_blocks(text):
    return [(m.span(), m.group(0), m.group(1)) for m in LATEX_RE.finditer(text)]

def render_latex_png_bytes(latex_code, fontsize=20, dpi=200):
    try:
        fig = plt.figure()
        fig.patch.set_alpha(0.0)
        fig.text(0, 0, f"${latex_code}$", fontsize=fontsize)
        buf = io.BytesIO()
        plt.axis('off')
        plt.savefig(buf, format='png', dpi=dpi, bbox_inches='tight', pad_inches=0.02, transparent=True)
        plt.close(fig)
        buf.seek(0)
        return buf.read()
    except Exception:
        return None

# -----------------------
# Xu·∫•t DOCX / PDF (GI·ªÆ NGUY√äN)
# -----------------------
def create_docx_bytes(text):
    doc = Document()
    last = 0
    for span, full, inner in find_latex_blocks(text):
        start, end = span
        before = text[last:start]
        for line in before.splitlines():
            doc.add_paragraph(line)
        try:
            png_bytes = render_latex_png_bytes(inner)
            if png_bytes:
                img_stream = io.BytesIO(png_bytes)
                p = doc.add_paragraph()
                r = p.add_run()
                r.add_picture(img_stream, width=Inches(3))
            else:
                doc.add_paragraph(full)
        except Exception:
            doc.add_paragraph(full)
        last = end
    for line in text[last:].splitlines():
        doc.add_paragraph(line)
    out = io.BytesIO()
    doc.save(out)
    out.seek(0)
    return out

def create_pdf_bytes(text):
    buf = io.BytesIO()
    c = canvas.Canvas(buf, pagesize=letter)
    width, height = letter
    margin = 40
    y = height - 50
    last = 0
    
    def check_page_break(current_y):
        if current_y < 60:
            c.showPage()
            return height - 50
        return current_y

    for span, full, inner in find_latex_blocks(text):
        start, end = span
        before = text[last:start]
        for line in before.splitlines():
            c.drawString(margin, y, line)
            y -= 14
            y = check_page_break(y)
        try:
            png_bytes = render_latex_png_bytes(inner)
            if png_bytes:
                img_reader = ImageReader(io.BytesIO(png_bytes))
                img = Image.open(io.BytesIO(png_bytes))
                draw_w = 300
                draw_h = img.height / img.width * draw_w
                if y - draw_h < 60:
                    c.showPage()
                    y = height - 50
                c.drawImage(img_reader, margin, y - draw_h, width=draw_w, height=draw_h, mask='auto')
                y -= draw_h + 8
            else:
                c.drawString(margin, y, full)
                y -= 14
        except Exception:
            c.drawString(margin, y, full)
            y -= 14
        y = check_page_break(y)
        last = end
    
    for line in text[last:].splitlines():
        c.drawString(margin, y, line)
        y -= 14
        y = check_page_break(y)
    
    c.save()
    buf.seek(0)
    return buf

# -----------------------
# H√ÄM GI√öP: X·ª≠ l√Ω API (GI·ªÆ NGUY√äN & B·ªî SUNG)
# -----------------------
def extract_text_from_api_response(data):
    if isinstance(data, dict) and "candidates" in data:
        cands = data.get("candidates") or []
        for cand in cands:
            text = deep_find_first_string(cand)
            if text: return text
    text = deep_find_first_string(data)
    return text if text else None

def deep_find_first_string(obj, keys=["text", "output", "content"]):
    if isinstance(obj, dict):
        for k in keys:
            if k in obj and isinstance(obj[k], str): return obj[k]
        for v in obj.values():
            res = deep_find_first_string(v, keys)
            if res: return res
    elif isinstance(obj, list):
        for item in obj:
            res = deep_find_first_string(item, keys)
            if res: return res
    return None

def generate_with_gemini(api_key, prompt, model=MODEL_DEFAULT):
    if not api_key: return {"ok": False, "message": "Thi·∫øu API Key."}
    url = f"https://generativelanguage.googleapis.com/v1/{model}:generateContent?key={api_key}"
    payload = {"contents":[{"role":"user","parts":[{"text":prompt}]}]}
    headers = {"Content-Type": "application/json"}
    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=60)
        data = resp.json()
        if "error" in data: return {"ok": False, "message": data["error"]["message"]}
        text = extract_text_from_api_response(data)
        if text: return {"ok": True, "text": text}
        return {"ok": False, "message": "Kh√¥ng t√¨m th·∫•y text.", "raw": data}
    except Exception as e:
        return {"ok": False, "message": str(e)}

# -----------------------
# T√çNH NƒÇNG M·ªöI: TEXT TO SPEECH
# -----------------------
def text_to_speech_bytes(text, lang='vi'):
    try:
        tts = gTTS(text=text, lang=lang)
        buf = io.BytesIO()
        tts.write_to_fp(buf)
        buf.seek(0)
        return buf
    except Exception as e:
        return None

# -----------------------
# GIAO DI·ªÜN CH√çNH (TABS)
# -----------------------
tab1, tab2, tab3, tab4 = st.tabs([
    "üìò T·ªïng h·ª£p Ki·∫øn th·ª©c", 
    "üìù Thi·∫øt k·∫ø Gi√°o √°n", 
    "üéµ S√°ng t√°c L·ªùi b√†i h√°t", 
    "üéß ƒê·ªçc VƒÉn b·∫£n (TTS)"
])

# --- TAB 1: T·ªîNG H·ª¢P KI·∫æN TH·ª®C (C·∫≠p nh·∫≠t: ch·ªçn Ch∆∞∆°ng/B√†i t·ª´ m·ª•c l·ª•c) ---
with tab1:
    st.subheader("T·ªïng h·ª£p ki·∫øn th·ª©c To√°n theo Ch∆∞∆°ng/B√†i (d·ª±a tr√™n m·ª•c l·ª•c upload)")
    col1, col2 = st.columns([1, 3])
    with col1:
        # l·ªõp available from index_structure keys
        classes = sorted([f"L·ªõp {k}" for k in index_structure.keys()], key=lambda x: int(re.search(r'\d+', x).group()))
        classes = ["T·∫•t c·∫£ l·ªõp"] + classes
        lop_sel = st.selectbox("Ch·ªçn l·ªõp:", classes, key="tab1_lop")

        # derive numeric class code if not "T·∫•t c·∫£ l·ªõp"
        sel_class_num = None
        if lop_sel != "T·∫•t c·∫£ l·ªõp":
            sel_class_num = re.search(r'\d+', lop_sel).group()

        # chapters list
        chapters_for_sel = []
        if sel_class_num:
            chapters_for_sel = index_structure.get(sel_class_num, [])
        else:
            # if all classes, combine chapters titles with class prefix
            combined = []
            for k in sorted(index_structure.keys(), key=lambda x: int(x)):
                for ch in index_structure[k]:
                    combined.append({"chapter_title": f"(L·ªõp {k}) {ch['chapter_title']}", "lessons": [f"(L·ªõp {k}) {l}" for l in ch.get("lessons", [])]})
            chapters_for_sel = combined

        chapter_titles = ["T·∫•t c·∫£ ch∆∞∆°ng", "To√†n ch∆∞∆°ng"]
        chapter_titles += [c["chapter_title"] for c in chapters_for_sel]
        chapter_sel = st.selectbox("Ch·ªçn ch∆∞∆°ng:", chapter_titles, key="tab1_chapter")

        # lessons
        lessons = []
        if chapter_sel in ["T·∫•t c·∫£ ch∆∞∆°ng", "To√†n ch∆∞∆°ng"]:
            # aggregate all lessons in class (or all classes)
            for c in chapters_for_sel:
                lessons.extend(c.get("lessons", []))
        else:
            # find selected chapter's lessons
            for c in chapters_for_sel:
                if c["chapter_title"] == chapter_sel:
                    lessons = c.get("lessons", [])
                    break
        lesson_options = ["To√†n b√†i"] + lessons if lessons else ["To√†n ch∆∞∆°ng (kh√¥ng c√≥ b√†i chi ti·∫øt)"]
        lesson_sel = st.selectbox("Ch·ªçn b√†i (n·∫øu mu·ªën):", lesson_options, key="tab1_lesson")

    if st.button("üöÄ T·ªïng h·ª£p ki·∫øn th·ª©c", key="btn_tab1"):
        # build prompt based on selection
        if lop_sel == "T·∫•t c·∫£ l·ªõp":
            scope = "To√†n b·ªô ch∆∞∆°ng tr√¨nh To√°n t·ª´ L·ªõp 6 ƒë·∫øn L·ªõp 9 theo m·ª•c l·ª•c ƒë√£ cung c·∫•p."
        else:
            scope = f"To√°n {lop_sel.replace('L·ªõp ','')}"
        if chapter_sel == "T·∫•t c·∫£ ch∆∞∆°ng":
            scope_detail = "T·ªïng h·ª£p to√†n b·ªô c√°c ch∆∞∆°ng c·ªßa l·ªõp ƒë∆∞·ª£c ch·ªçn, theo t·ª´ng ch∆∞∆°ng v√† t·ª´ng b√†i (n√™u m·ª•c ti√™u, kh√°i ni·ªám, c√¥ng th·ª©c v·ªõi LaTeX $$...$$ v√† v√≠ d·ª• minh h·ªça)."
        elif chapter_sel == "To√†n ch∆∞∆°ng":
            scope_detail = "T·ªïng h·ª£p n·ªôi dung chi ti·∫øt cho to√†n ch∆∞∆°ng(s) ƒë√£ ch·ªçn."
        else:
            # specific chapter selected
            if lesson_sel == "To√†n b√†i":
                scope_detail = f"T·ªïng h·ª£p to√†n b·ªô n·ªôi dung c·ªßa {chapter_sel} (theo m·ª•c l·ª•c), ph√¢n chia Kh√°i ni·ªám ‚Äì C√¥ng th·ª©c (LaTeX trong $$...$$) ‚Äì V√≠ d·ª• cho t·ª´ng b√†i."
            else:
                scope_detail = f"T·ªïng h·ª£p chuy√™n s√¢u cho: {lesson_sel} (thu·ªôc {chapter_sel}), c·∫•u tr√∫c: Kh√°i ni·ªám ‚Äì C√¥ng th·ª©c (LaTeX trong $$...$$) ‚Äì V√≠ d·ª•, c√¢u h·ªèi luy·ªán t·∫≠p v√† h∆∞·ªõng d·∫´n gi·∫£i ng·∫Øn."

        prompt = f"""
B·∫°n l√† gi√°o vi√™n To√°n c√≥ kinh nghi·ªám. H√£y { 'so·∫°n t√†i li·ªáu' if 'T·ªïng h·ª£p' in scope_detail else 't·ªïng h·ª£p' } {scope}.
Y√™u c·∫ßu:
- PH·∫†M VI: {scope_detail}
- PH√ÇN NH√ìM n·ªôi dung (n·∫øu ph√π h·ª£p): S·ªë h·ªçc, ƒê·∫°i s·ªë, H√¨nh h·ªçc, Th·ªëng k√™.
- C·∫§U TR√öC: M·ªói m·ª•c/b√†i tr√¨nh b√†y theo: M·ª•c ti√™u (Ki·∫øn th·ª©c, NƒÉng l·ª±c, Ph·∫©m ch·∫•t) ‚Äì Kh√°i ni·ªám ‚Äì C√¥ng th·ª©c (vi·∫øt b·∫±ng LaTeX trong $$...$$ n·∫øu c√≥) ‚Äì V√≠ d·ª• minh h·ªça ‚Äì B√†i t·∫≠p luy·ªán t·∫≠p (k√®m ƒë√°p √°n t√≥m t·∫Øt).
- Tr√¨nh b√†y r√µ r√†ng, ph√π h·ª£p ƒë·ªÉ in ·∫•n, c√≥ ti√™u ƒë·ªÅ v√† ƒë√°nh s·ªë ch∆∞∆°ng/b√†i.
- Ng√¥n ng·ªØ: ti·∫øng Vi·ªát chu·∫©n, ph√π h·ª£p h·ªçc sinh trung h·ªçc c∆° s·ªü.
- N·∫øu n·ªôi dung c√≥ th·ªÉ minh h·ªça b·∫±ng h√¨nh/h·ªá qu·∫£, h√£y ghi ch√∫ ch·ªó c·∫ßn h√¨nh (v√≠ d·ª•: [Ch√®n h√¨nh: H√¨nh tam gi√°c vu√¥ng]).
Tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng vƒÉn b·∫£n d·ªÖ copy/paste.
        """
        with st.spinner("ƒêang t·ªïng h·ª£p..."):
            res = generate_with_gemini(api_key, prompt)
            if res["ok"]:
                st.session_state["summary_text"] = res["text"]
            else:
                st.error(res["message"])

    # hi·ªÉn th·ªã v√† n√∫t t·∫£i v·ªÅ
    if "summary_text" in st.session_state:
        st.markdown(st.session_state["summary_text"].replace("\n", "<br>"), unsafe_allow_html=True)
        col_d1, col_d2 = st.columns(2)
        with col_d1:
            docx = create_docx_bytes(st.session_state["summary_text"])
            st.download_button("üì• T·∫£i DOCX", docx, "KienThucToan.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        with col_d2:
            pdf = create_pdf_bytes(st.session_state["summary_text"])
            st.download_button("üì• T·∫£i PDF", pdf, "KienThucToan.pdf", "application/pdf")

# --- TAB 2: THI·∫æT K·∫æ GI√ÅO √ÅN (M·ªõi) ---
with tab2:
    st.subheader("Tr·ª£ l√Ω so·∫°n gi√°o √°n (Lesson Plan)")
    c1, c2, c3 = st.columns(3)
    with c1:
        ga_lop = st.selectbox("L·ªõp:", [f"L·ªõp {i}" for i in range(1, 10)], key="ga_lop")
    with c2:
        ga_bai = st.text_input("T√™n b√†i h·ªçc:", "Ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t m·ªôt ·∫©n")
    with c3:
        ga_phut = st.number_input("Th·ªùi l∆∞·ª£ng (ph√∫t):", value=45)

    ga_yeucau = st.text_area("Y√™u c·∫ßu th√™m (VD: ho·∫°t ƒë·ªông nh√≥m, tr√≤ ch∆°i, ·ª©ng d·ª•ng th·ª±c t·∫ø...):", height=100)

    if st.button("‚úçÔ∏è So·∫°n gi√°o √°n", key="btn_ga"):
        prompt_ga = f"""
        So·∫°n gi√°o √°n chi ti·∫øt cho b√†i h·ªçc: "{ga_bai}" m√¥n To√°n {ga_lop}.
        Th·ªùi l∆∞·ª£ng: {ga_phut} ph√∫t.
        Y√™u c·∫ßu ƒë·∫∑c bi·ªát: {ga_yeucau}.
        C·∫•u tr√∫c gi√°o √°n (theo h∆∞·ªõng ph√°t tri·ªÉn nƒÉng l·ª±c):
        1. M·ª•c ti√™u (Ki·∫øn th·ª©c, NƒÉng l·ª±c, Ph·∫©m ch·∫•t).
        2. Chu·∫©n b·ªã (GV, HS).
        3. Ti·∫øn tr√¨nh d·∫°y h·ªçc:
           - Ho·∫°t ƒë·ªông 1: Kh·ªüi ƒë·ªông (M·ªü ƒë·∫ßu).
           - Ho·∫°t ƒë·ªông 2: H√¨nh th√†nh ki·∫øn th·ª©c m·ªõi.
           - Ho·∫°t ƒë·ªông 3: Luy·ªán t·∫≠p.
           - Ho·∫°t ƒë·ªông 4: V·∫≠n d·ª•ng & T√¨m t√≤i m·ªü r·ªông.
        Tr√¨nh b√†y chi ti·∫øt ho·∫°t ƒë·ªông c·ªßa GV v√† HS.
        """
        with st.spinner("ƒêang so·∫°n gi√°o √°n..."):
            res = generate_with_gemini(api_key, prompt_ga)
            if res["ok"]:
                st.session_state["plan_text"] = res["text"]
            else:
                st.error(res["message"])

    if "plan_text" in st.session_state:
        st.markdown("---")
        st.markdown(st.session_state["plan_text"])
        docx_ga = create_docx_bytes(st.session_state["plan_text"])
        # Make filename safe
        safe_name = re.sub(r'[\\/*?:"<>|]',"_", ga_bai)
        st.download_button("üì• T·∫£i Gi√°o √°n (DOCX)", docx_ga, f"GiaoAn_{safe_name}.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")

# --- TAB 3: CH·∫æ L·ªúI B√ÄI H√ÅT (M·ªõi) ---
with tab3:
    st.subheader("S√°ng t√°c nh·∫°c To√°n h·ªçc üéµ")
    st.write("Bi·∫øn c√¥ng th·ª©c kh√¥ khan th√†nh giai ƒëi·ªáu d·ªÖ nh·ªõ!")
    
    col_music1, col_music2 = st.columns(2)
    with col_music1:
        music_topic = st.text_input("Ch·ªß ƒë·ªÅ to√°n mu·ªën ph·ªï nh·∫°c:", "B·∫£ng c·ª≠u ch∆∞∆°ng 7")
    with col_music2:
        music_style = st.selectbox("Phong c√°ch nh·∫°c:", ["Rap s√¥i ƒë·ªông", "V√® d√¢n gian", "H√≤ ƒë·ªëi ƒë√°p", "Pop Ballad nh·∫π nh√†ng", "Th∆° l·ª•c b√°t"])

    if st.button("üé§ S√°ng t√°c ngay", key="btn_music"):
        prompt_music = f"""
        H√£y ƒë√≥ng vai m·ªôt nh·∫°c sƒ© t√†i ba. S√°ng t√°c l·ªùi b√†i h√°t v·ªÅ ch·ªß ƒë·ªÅ to√°n h·ªçc: "{music_topic}".
        Phong c√°ch: {music_style}.
        ƒê·ªëi t∆∞·ª£ng: H·ªçc sinh.
        Y√™u c·∫ßu:
        - L·ªùi l·∫Ω vui t∆∞∆°i, h√≥m h·ªânh, d·ªÖ nh·ªõ.
        - L·ªìng gh√©p ch√≠nh x√°c ki·∫øn th·ª©c to√°n h·ªçc.
        - C√≥ ph√¢n ƒëo·∫°n r√µ r√†ng (Verse, Chorus/ƒêi·ªáp kh√∫c).
        """
        with st.spinner("Nh·∫°c sƒ© AI ƒëang phi√™u..."):
            res = generate_with_gemini(api_key, prompt_music)
            if res["ok"]:
                st.session_state["lyrics_text"] = res["text"]
            else:
                st.error(res["message"])

    if "lyrics_text" in st.session_state:
        st.info("üí° G·ª£i √Ω: B·∫°n c√≥ th·ªÉ copy l·ªùi n√†y v√† d√πng Suno AI ho·∫∑c Udio ƒë·ªÉ t·∫°o nh·∫°c beat!")
        st.text_area("L·ªùi b√†i h√°t:", st.session_state["lyrics_text"], height=300)
        
        # N√∫t ƒë·ªçc th·ª≠ l·ªùi b√†i h√°t
        if st.button("üîä Nghe l·ªùi b√†i h√°t (ƒê·ªçc m·∫´u)", key="btn_read_lyrics"):
            audio_bytes = text_to_speech_bytes(st.session_state["lyrics_text"])
            if audio_bytes:
                st.audio(audio_bytes, format='audio/mp3')

# --- TAB 4: ƒê·ªåC VƒÇN B·∫¢N (TTS) (M·ªõi) ---
with tab4:
    st.subheader("C√¥ng c·ª• ƒê·ªçc vƒÉn b·∫£n (Text-to-Speech)")
    tts_text = st.text_area("Nh·∫≠p vƒÉn b·∫£n mu·ªën ƒë·ªçc:", "Ch√†o c√°c em h·ªçc sinh, h√¥m nay ch√∫ng ta s·∫Ω h·ªçc b√†i ƒê·ªãnh l√Ω Py-ta-go.")
    
    c_tts1, c_tts2 = st.columns([1, 4])
    with c_tts1:
        lang_code = st.selectbox("Ng√¥n ng·ªØ:", ["vi", "en"])
    
    if st.button("‚ñ∂Ô∏è ƒê·ªçc ngay", key="btn_tts"):
        if tts_text:
            with st.spinner("ƒêang t·∫°o file √¢m thanh..."):
                audio_data = text_to_speech_bytes(tts_text, lang=lang_code)
                if audio_data:
                    st.success("ƒê√£ t·∫°o xong!")
                    st.audio(audio_data, format='audio/mp3')
                else:
                    st.error("L·ªói khi t·∫°o √¢m thanh (ki·ªÉm tra k·∫øt n·ªëi m·∫°ng).")
        else:
            st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung c·∫ßn ƒë·ªçc.")

# -----------------------
# Footer
# -----------------------
st.markdown("---")
st.caption("Developed with ‚ù§Ô∏è using Streamlit & Gemini AI.")
